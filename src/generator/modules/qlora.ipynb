{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9640ab93",
   "metadata": {},
   "source": [
    "# **üçÄQwen 8B - QLoRA** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f77444",
   "metadata": {},
   "source": [
    "## **1. ÎùºÏù¥Î∏åÎü¨Î¶¨ Ìò∏Ï∂ú**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fac73a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:36<00:00, 19.21s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import torch\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, PeftModel\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig, Trainer, DataCollatorForLanguageModeling\n",
    "from trl import SFTTrainer\n",
    "from model_load import tokenizer, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b1315f",
   "metadata": {},
   "source": [
    "## **2. Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da9ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_dict(docs):\n",
    "    context_dict = {}\n",
    "    for doc in docs:\n",
    "        source_id = doc[\"metadata\"].get(\"source_id\")\n",
    "        chunk_id = doc[\"metadata\"].get(\"chunk_id\")\n",
    "        if source_id and chunk_id:\n",
    "            context_dict[(source_id, chunk_id)] = doc[\"text\"]\n",
    "    return context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f52570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sft_format(qa_path, context_dict, output_path):\n",
    "    with open(qa_path, \"r\", encoding=\"utf-8\") as f_in, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        for line in f_in:\n",
    "            qa = json.loads(line.strip())\n",
    "            key = (qa[\"source_id\"], qa[\"chunk_id\"])\n",
    "            context = context_dict.get(key, \"\")\n",
    "            sft_item = {\n",
    "                \"input\": f\"Î¨∏ÏÑú ÎÇ¥Ïö©:\\n{context}\\n\\nÏßàÎ¨∏:\\n{qa['Question']}\",\n",
    "                \"output\": qa[\"Answer\"]\n",
    "            }\n",
    "            f_out.write(json.dumps(sft_item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165babfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d96508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏõêÎ≥∏ Î¨∏ÏÑú Î∂àÎü¨Ïò§Í∏∞\n",
    "dummy_dir = \"/home/NEUL77/AI-Engineer/data/dummy\"\n",
    "jsonl_files = glob(os.path.join(dummy_dir, \"*.jsonl\"))\n",
    "\n",
    "docs = []\n",
    "for file_path in jsonl_files:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            docs.append({\n",
    "                \"text\": data[\"text\"],\n",
    "                \"metadata\": data.get(\"metadata\", {})\n",
    "            })\n",
    "\n",
    "# source_id + chunk_id Í∏∞Î∞ò context dict ÏÉùÏÑ±\n",
    "context_dict = build_context_dict(docs)\n",
    "\n",
    "# QA + context ‚Üí SFT Ìè¨Îß∑ Î≥ÄÌôò\n",
    "qa_path = \"/home/NEUL77/AI-Engineer/data/train/qa_dataset.jsonl\"\n",
    "output_path = \"/home/NEUL77/AI-Engineer/data/train/qa_sft_dataset.jsonl\"\n",
    "convert_to_sft_format(qa_path, context_dict, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b664e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_fields(input_path, output_path):\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f_in, \\\n",
    "         open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "\n",
    "        for line in f_in:\n",
    "            item = json.loads(line.strip())\n",
    "\n",
    "            full_input = item.get(\"input\", \"\")\n",
    "            output = item.get(\"output\", \"\")\n",
    "\n",
    "            # \"Î¨∏ÏÑú ÎÇ¥Ïö©:\"Í≥º \"ÏßàÎ¨∏:\" Í∏∞Ï§ÄÏúºÎ°ú Î∂ÑÎ¶¨\n",
    "            try:\n",
    "                doc_part, question_part = full_input.split(\"ÏßàÎ¨∏:\")\n",
    "                doc_text = doc_part.replace(\"Î¨∏ÏÑú ÎÇ¥Ïö©:\", \"\").strip()\n",
    "                question_text = question_part.strip()\n",
    "\n",
    "                new_item = {\n",
    "                    \"instruction\": question_text,  # ÏßàÎ¨∏\n",
    "                    \"input\": doc_text,             # Î¨∏ÏÑú ÎÇ¥Ïö©\n",
    "                    \"output\": output               # Ï†ïÎãµ\n",
    "                }\n",
    "                f_out.write(json.dumps(new_item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"‚ö†Ô∏è ÏûòÎ™ªÎêú ÌòïÏãùÏùò input ÌïÑÎìúÍ∞Ä ÏûàÏäµÎãàÎã§. Í±¥ÎÑàÎúÅÎãàÎã§.\")\n",
    "                continue\n",
    "\n",
    "    print(f\"[‚úî] Î∂ÑÎ¶¨ ÏôÑÎ£å: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d988c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úî] Î∂ÑÎ¶¨ ÏôÑÎ£å: /home/NEUL77/AI-Engineer/data/train/qa_sft_dataset_split.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
    "input_path = \"/home/NEUL77/AI-Engineer/data/train/qa_sft_dataset.jsonl\"\n",
    "output_path = \"/home/NEUL77/AI-Engineer/data/train/qa_sft_dataset_split.jsonl\"\n",
    "\n",
    "# Ïã§Ìñâ\n",
    "split_input_fields(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503f2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(data_path):\n",
    "    dataset = []\n",
    "\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line.strip())\n",
    "            dataset.append({\n",
    "                \"instruction\": item[\"instruction\"],  # ÏßàÎ¨∏\n",
    "                \"input\": item[\"input\"],              # Î¨∏ÏÑú ÎÇ¥Ïö©\n",
    "                \"output\": item[\"output\"]             # Ï†ïÎãµ\n",
    "            })\n",
    "\n",
    "    train_data, test_data = train_test_split(dataset, test_size=0.2, shuffle=True, random_state=42)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b9194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data_loader(\"/home/NEUL77/AI-Engineer/data/train/qa_sft_dataset_split.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f03109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528\n",
      "382\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520cfc4",
   "metadata": {},
   "source": [
    "## **3. Îç∞Ïù¥ÌÑ∞ Ìè¨Îß∑ Ï†ïÏ†ú**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7daa5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG ÌïôÏäµÏùÑ ÏúÑÌïú ChatML ÌòïÏãù Ìï®Ïàò\n",
    "def to_chatml_rag_format(data):\n",
    "    formatted = []\n",
    "    for item in data:\n",
    "        # ÏãúÏä§ÌÖú Î©îÏãúÏßÄ\n",
    "        prompt_parts = [\n",
    "            \"<|im_start|>system\\nÎãπÏã†ÏùÄ 'ÏûÖÏ∞∞Î©îÏù¥Ìä∏' Í∏∞ÏóÖÏùò ÏûÖÏ∞∞ Ï†ÑÎ¨∏ Ïª®ÏÑ§ÌÑ¥Ìä∏ AIÏûÖÎãàÎã§. Ï†úÍ≥µÎêú Î¨∏ÏÑúÎ•º Í∏∞Î∞òÏúºÎ°ú ÏßàÎ¨∏Ïóê ÎãµÎ≥ÄÌï©ÎãàÎã§.\\n<|im_end|>\\n\",\n",
    "        ]\n",
    "        \n",
    "        # context(input)Í∞Ä ÏûàÎäî Í≤ΩÏö∞\n",
    "        if item.get(\"input\"):\n",
    "            prompt_parts.append(\"<|im_start|>user\\nÎ¨∏ÏÑú:\\n\" + item[\"input\"].strip() + \"\\n\\nÏßàÎ¨∏:\\n\" + item[\"instruction\"].strip() + \"<|im_end|>\\n\")\n",
    "        else:\n",
    "            prompt_parts.append(\"<|im_start|>user\\n\" + item[\"instruction\"].strip() + \"<|im_end|>\\n\")\n",
    "\n",
    "        # ÎãµÎ≥Ä (output)\n",
    "        prompt_parts.append(\"<|im_start|>assistant\\n\" + item[\"output\"].strip() + \"<|im_end|>\")\n",
    "\n",
    "        prompt = \"\".join(prompt_parts)\n",
    "        formatted.append({\"text\": prompt})\n",
    "    return formatted\n",
    "\n",
    "# ÏÉàÎ°úÏö¥ Ìï®ÏàòÎ•º ÏÇ¨Ïö©ÌïòÏó¨ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ±\n",
    "train_chatml = to_chatml_rag_format(train_data)\n",
    "test_chatml = to_chatml_rag_format(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deff13b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Í∏∏Ïù¥ ÌÜµÍ≥Ñ >\n",
      "‚Üí ÌèâÍ∑† Í∏∏Ïù¥: 1039.44\n",
      "‚Üí Ï§ëÏïôÍ∞í: 958.0\n",
      "‚Üí ÏµúÎåÄ Í∏∏Ïù¥: 4783\n",
      "‚Üí ÏÉÅÏúÑ 95% Í∏∏Ïù¥: 1959.8499999999988\n"
     ]
    }
   ],
   "source": [
    "# Í∞Å ChatML Î¨∏Ïû•Ïùò Í∏∏Ïù¥Î•º Ï∏°Ï†ï\n",
    "lengths = [len(tokenizer(item[\"text\"])[\"input_ids\"]) for item in train_chatml]\n",
    "\n",
    "# Í∏∏Ïù¥ ÌÜµÍ≥Ñ Î≥¥Í∏∞\n",
    "print(\"< Í∏∏Ïù¥ ÌÜµÍ≥Ñ >\")\n",
    "print(f\"‚Üí ÌèâÍ∑† Í∏∏Ïù¥: {np.mean(lengths):.2f}\")\n",
    "print(f\"‚Üí Ï§ëÏïôÍ∞í: {np.median(lengths)}\")\n",
    "print(f\"‚Üí ÏµúÎåÄ Í∏∏Ïù¥: {np.max(lengths)}\")\n",
    "print(f\"‚Üí ÏÉÅÏúÑ 95% Í∏∏Ïù¥: {np.percentile(lengths, 95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ba33b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = Dataset.from_list(train_chatml)\n",
    "dataset_test = Dataset.from_list(test_chatml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da54bdfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 1528\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "518aa3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1528 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1528/1528 [00:02<00:00, 724.70 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [00:00<00:00, 936.94 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=True,          # ÎèôÏ†Å Ìå®Îî© ‚Üí ÎÇ≠ÎπÑ ÏµúÏÜåÌôî\n",
    "        truncation=True,\n",
    "        max_length=256         # Í∏∏Ïù¥ Î∂ÑÏÑùÏóê Îî∞Î•∏ ÏÑ§Ï†ï\n",
    "    )\n",
    "\n",
    "tokenized_train = dataset_train.map(tokenize, batched=True)\n",
    "tokenized_test = dataset_test.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5efd997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 1528\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07866748",
   "metadata": {},
   "source": [
    "## **4. Î™®Îç∏ ÌïôÏäµ Ï§ÄÎπÑ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e393e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA ÌïôÏäµ Ï§ÄÎπÑ\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA ÏÑ§Ï†ï\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    ")\n",
    "\n",
    "# LoRA Ï†ÅÏö©\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b722c157",
   "metadata": {},
   "source": [
    "## **5. Î™®Îç∏ ÌïôÏäµ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7aec4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/miniconda/envs/team2_env/lib/python3.11/site-packages (25.1.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement install (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for install\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pip install -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a75cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e046c36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/peft/mapping_func.py:79: UserWarning: The PEFT config's `base_model_name_or_path` was renamed from 'Qwen/Qwen3-8B' to 'None'. Please ensure that the correct base model is loaded when loading this checkpoint.\n",
      "  warnings.warn(\n",
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "Adding EOS to train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1528/1528 [00:00<00:00, 17072.23 examples/s]\n",
      "Tokenizing train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1528/1528 [00:04<00:00, 356.97 examples/s]\n",
      "Truncating train dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1528/1528 [00:00<00:00, 52375.24 examples/s]\n",
      "Adding EOS to eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [00:00<00:00, 16866.05 examples/s]\n",
      "Tokenizing eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [00:00<00:00, 383.69 examples/s]\n",
      "Truncating eval dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 382/382 [00:00<00:00, 82948.03 examples/s]\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='402' max='1146' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 402/1146 54:35 < 1:41:33, 0.12 it/s, Epoch 1.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.469500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.306600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.261500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.173000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.116200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.194000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>1.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.094500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.076400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.959900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.048500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# SFTTrainerÎ°ú ÌïôÏäµ\u001b[39;00m\n\u001b[32m     23\u001b[39m trainer = SFTTrainer(\n\u001b[32m     24\u001b[39m     model=model,\n\u001b[32m     25\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     peft_config=lora_config\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m trainer.model.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33mresults/qlora_qwen3_8b_v2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m tokenizer.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33mresults/qlora_qwen3_8b_v2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/transformers/trainer.py:2238\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2236\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2239\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/transformers/trainer.py:2582\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2575\u001b[39m context = (\n\u001b[32m   2576\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2577\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2579\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2580\u001b[39m )\n\u001b[32m   2581\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2582\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2584\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2585\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2586\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2587\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2588\u001b[39m ):\n\u001b[32m   2589\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2590\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:904\u001b[39m, in \u001b[36mSFTTrainer.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    902\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    903\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maybe_activation_offload_context:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/transformers/trainer.py:3845\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   3842\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   3843\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3845\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3847\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/accelerate/accelerator.py:2578\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2576\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2578\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ÌïôÏäµ ÏÑ§Ï†ï\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results_v2/qlora_qwen3_8b_v2\",\n",
    "    logging_dir=\"results_v2/logs\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    bf16=True,\n",
    "    learning_rate=1e-4,\n",
    "    max_grad_norm=0.3,\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None,\n",
    ")\n",
    "\n",
    "# SFTTrainerÎ°ú ÌïôÏäµ\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    peft_config=lora_config\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.model.save_pretrained(\"results/qlora_qwen3_8b_v2\")\n",
    "tokenizer.save_pretrained(\"results/qlora_qwen3_8b_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa55c9c",
   "metadata": {},
   "source": [
    "## **6. Î™®Îç∏ Î≥ëÌï©**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c823e",
   "metadata": {},
   "source": [
    "### 6.1 Ï≤¥ÌÅ¨Ìè¨Ïù∏Ìä∏ ÌèâÍ∞Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f1b158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/peft/peft_model.py:585: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-100 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? \n",
      "\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®ÏùÄ ÎåÄÌïúÎØºÍµ≠Ïùò ÏÇ¨ÌöåÎ≥¥Ïû•Ï†úÎèÑ Ï§ë ÌïòÎÇòÏù∏ Íµ≠ÎØºÏó∞Í∏àÏùò Ïö¥ÏòÅÏùÑ Îã¥ÎãπÌïòÎäî Í≥µÍ≥µÍ∏∞Í¥ÄÏûÖÎãàÎã§. Îî∞ÎùºÏÑú Í∑∏ Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Íµ≠ÎØºÏó∞Í∏àÏùò **ÏïàÏ†ïÏ†ÅÏù∏ Ïö¥ÏòÅ**, **Í≥µÏ†ïÏÑ±**, **Ìà¨Î™ÖÏÑ±**, **ÏßÄÏÜçÍ∞ÄÎä•ÏÑ±** Îì±Í≥º Í∞ôÏùÄ ÏõêÏπôÏùÑ Ï§ëÏã¨ÏúºÎ°ú ÏÑ§Ï†ïÎê©ÎãàÎã§. Íµ¨Ï≤¥Ï†ÅÏúºÎ°úÎäî Îã§ÏùåÍ≥º\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-1000 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? Íµ≠ÎØºÏó∞Í∏àÍ≥µ\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-1100 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®ÏùÄ ÎåÄÌïúÎØºÍµ≠Ïùò Ï£ºÏöî ÏÇ¨ÌöåÏïàÏ†ÑÎßù Í∏∞Í¥Ä Ï§ë ÌïòÎÇòÎ°úÏÑú, Íµ≠ÎØºÏó∞Í∏àÏùò Ïö¥ÏòÅÍ≥º Í¥ÄÎ¶¨Î•º Îã¥ÎãπÌïòÍ≥† ÏûàÏäµÎãàÎã§. Ïù¥ Í∏∞Í¥ÄÏùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ïó¨Îü¨ Ï∏°Î©¥ÏóêÏÑú ÎÇòÌÉÄÎÇ©ÎãàÎã§:\n",
      "\n",
      "1. **ÏïàÏ†ïÏ†ÅÏù∏ Ïó∞Í∏à ÏàòÍ∏â**: Íµ≠ÎØºÏó∞Í∏àÏùò ÏßÄÏÜç Í∞ÄÎä•Ìïú Ïö¥ÏòÅÏùÑ ÏúÑÌï¥ Í≥†Î†πÌôî ÏÇ¨ÌöåÏóê ÎåÄÏùëÌïòÎäî ÏàòÍ∏â Ï≤¥Í≥ÑÎ•º Ïú†ÏßÄÌïòÍ≥†, Ïó∞Í∏à ÏàòÍ∏âÏï°\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-1146 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ?\n",
      "\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ïó¨Îü¨ Í∞ÄÏßÄ Ï∏°Î©¥ÏóêÏÑú Îã§Î•º Ïàò ÏûàÏßÄÎßå, ÏùºÎ∞òÏ†ÅÏúºÎ°ú Îã§ÏùåÍ≥º Í∞ôÏùÄ ÎÇ¥Ïö©ÏùÑ Ìè¨Ìï®Ìï©ÎãàÎã§:\n",
      "\n",
      "1. **ÏïàÏ†ïÏ†ÅÏù∏ Ïó∞Í∏à ÏàòÍ∏â**: Íµ≠ÎØºÏó∞Í∏àÏùÑ ÌÜµÌï¥ Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏàòÍ∏âÎ∞õÏùÑ Ïàò ÏûàÎèÑÎ°ù Ïó∞Í∏à ÏàòÏ§ÄÏùò ÏïàÏ†ïÏÑ±Í≥º ÏßÄÏÜçÏÑ±ÏùÑ ÌôïÎ≥¥ÌïòÎäî Í≤ÉÏù¥ ÌïµÏã¨ÏûÖÎãàÎã§. Ïù¥Îäî Ïû•Í∏∞Ï†ÅÏù∏ Ïû¨Ï†ï\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-200 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§. Î®ºÏ†Ä, Íµ≠ÎØºÏó∞Í∏àÏùÄ ÎåÄÌïúÎØºÍµ≠Ïùò ÏÇ¨ÌöåÎ≥¥Ïû•Ï†úÎèÑ Ï§ë ÌïòÎÇòÎ°ú, Íµ≠ÎØºÏùò ÎÖ∏ÌõÑ ÏÉùÌôúÏùÑ Î≥¥Ïû•ÌïòÍ∏∞ ÏúÑÌïú Ïó≠Ìï†ÏùÑ Ìï©ÎãàÎã§. Îî∞ÎùºÏÑú, Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ï∏°Î©¥ÏóêÏÑú ÎÇòÌÉÄÎÇ©ÎãàÎã§.\n",
      "\n",
      "1. **ÏïàÏ†ïÏ†ÅÏù∏ Ïó∞Í∏à ÏàòÍ∏â**: Íµ≠ÎØº\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-300 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Í∑∏Î¶¨Í≥† Í∑∏ ÏöîÍµ¨ÏÇ¨Ìï≠Ïùò Í∑ºÍ±∞Îäî Î¨¥ÏóáÏù∏Í∞ÄÏöî? ÎòêÌïú, Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï°∞ÏßÅÍµ¨Ï°∞Îäî Ïñ¥ÎñªÍ≤å ÎêòÍ≥†, Í∞Å Î∂ÄÏÑúÏùò Ïó≠Ìï†ÏùÄ Î¨¥ÏóáÏù∏ÏßÄ ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî. ÎßàÏßÄÎßâÏúºÎ°ú, Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏÇ¨ÏóÖÏùÄ Î¨¥ÏóáÏù¥Î©∞, Í∑∏ ÏÇ¨ÏóÖÏùò ÌäπÏßïÍ≥º Î™©Ï†ÅÏùÄ Î¨¥ÏóáÏù∏ÏßÄ ÏÑ§Î™ÖÌï¥ Ï£ºÏÑ∏Ïöî.\n",
      "\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Ï£ºÎ°ú Íµ≠ÎØºÏùò Ïó∞Í∏à ÏàòÎ†πÍ∂å Î≥¥Ïû•ÏùÑ ÏúÑÌïú ÔøΩ\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-400 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§:\n",
      "\n",
      "1. **Íµ≠ÎØºÏó∞Í∏àÏùò ÏïàÏ†ïÏ†Å Ïö¥ÏòÅ**  \n",
      "   - Íµ≠ÎØºÏó∞Í∏àÏùò Ïû•Í∏∞Ï†Å Ïû¨Ï†ï ÏïàÏ†ïÏÑ±ÏùÑ ÌôïÎ≥¥ÌïòÍ∏∞ ÏúÑÌï¥ ÏßÄÏÜç Í∞ÄÎä•Ìïú ÏàòÏùµÎ•†ÏùÑ Ïú†ÏßÄÌïòÍ≥†, Ï†ÅÏ†ïÌïú Ïó∞Í∏àÏï°ÏùÑ ÏßÄÍ∏âÌïòÎäî Í≤ÉÏù¥ ÌïµÏã¨ÏûÖÎãàÎã§.  \n",
      "   - Ìà¨Ïûê ÏàòÏùµÎ•† Ïú†ÏßÄ, Ï†ÅÎ¶ΩÍ∏à ÌôïÎ≥¥, Ïû¨Ï†ï Í±¥Ï†ÑÏÑ± Í∞ïÌôîÍ∞Ä Ï§ëÏöîÌï©ÎãàÎã§\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-500 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî? \n",
      "\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®ÏùÄ ÎåÄÌïúÎØºÍµ≠Ïùò ÏÇ¨ÌöåÎ≥¥Ïû•Ï†úÎèÑ Ï§ë ÌïòÎÇòÏù∏ Íµ≠ÎØºÏó∞Í∏àÏùò Ïö¥ÏòÅÏùÑ Îã¥ÎãπÌïòÎäî Í∏∞Í¥ÄÏûÖÎãàÎã§. Îî∞ÎùºÏÑú Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Îã§ÏñëÌïú Ï∏°Î©¥ÏóêÏÑú ÎÇòÎàå Ïàò ÏûàÏäµÎãàÎã§. ÏïÑÎûòÎäî Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ Ï†ïÎ¶¨Ìïú Í≤ÉÏûÖÎãàÎã§:\n",
      "\n",
      "### 1. **ÏïàÏ†ïÏ†ÅÏù∏ Ïó∞Í∏à ÏàòÍ∏â ÌôïÎ≥¥\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-600 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ?Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ?\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ï£ºÏ†úÏóê ÎåÄÌïú Ï†ïÎ≥¥Î•º Ìè¨Ìï®Ìï©ÎãàÎã§:\n",
      "\n",
      "1. Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Î™©Ï†Å: Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®ÏùÄ ÎåÄÌïúÎØºÍµ≠Ïùò Íµ≠ÎØºÏó∞Í∏àÏùÑ Í¥ÄÎ¶¨ÌïòÎäî Í≥µÍ≥µÍ∏∞Í¥ÄÏúºÎ°ú, ÎåÄÌïúÎØºÍµ≠Ïùò ÎÖ∏ÌõÑ ÏïàÏ†ÑÏùÑ ÏúÑÌï¥ Íµ≠ÎØºÏó∞Í∏àÏùÑ Í¥ÄÎ¶¨ÌïòÍ≥† Ïö¥ÏòÅÌï©ÎãàÎã§. Ïù¥ Í∏∞Í¥ÄÏùò Ï£ºÏöî Î™©Ï†ÅÏùÄ ÎÖ∏Ïù∏Ïùò ÔøΩ\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-700 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ?\n",
      "\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®ÏùÄ ÎåÄÌïúÎØºÍµ≠Ïùò ÏÇ¨ÌöåÎ≥¥Ïû•Ï†úÎèÑ Ï§ë ÌïòÎÇòÏù∏ Íµ≠ÎØºÏó∞Í∏àÏùÑ Í¥ÄÎ¶¨ÌïòÎäî Í∏∞Í¥ÄÏûÖÎãàÎã§. Í∑∏ Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Ïó¨Îü¨ Í∞ÄÏßÄÎ°ú ÎÇòÎàå Ïàò ÏûàÏäµÎãàÎã§:\n",
      "\n",
      "1. **ÏïàÏ†ïÏ†ÅÏù∏ Ïû¨Ï†ï Í¥ÄÎ¶¨**: Íµ≠ÎØºÏó∞Í∏àÏùÄ Ïû•Í∏∞Ï†ÅÏù∏ Ïû¨Ï†ï ÏïàÏ†ïÏÑ±ÏùÑ Ïú†ÏßÄÌïòÍ∏∞ ÏúÑÌï¥ ÏßÄÏÜç Í∞ÄÎä•Ìïú ÏàòÏùµÎ•†ÏùÑ Îã¨ÏÑ±ÌïòÍ≥†, Ìñ•ÌõÑ Ïó∞\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-800 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Î¨¥ÏóáÏù∏Í∞ÄÏöî?\n",
      "\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®ÏùÄ ÎåÄÌïúÎØºÍµ≠Ïùò ÏÇ¨ÌöåÎ≥¥Ïû•Ï†úÎèÑ Ï§ë ÌïòÎÇòÏù∏ Íµ≠ÎØºÏó∞Í∏àÏùÑ Ïö¥ÏòÅÌïòÎäî Í∏∞Í¥ÄÏûÖÎãàÎã§. Îî∞ÎùºÏÑú Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏùÄ Î∞©Ìñ•ÏúºÎ°ú ÏÑ§Ï†ïÎê©ÎãàÎã§:\n",
      "\n",
      "1. **Ïû¨Ï†ï ÏïàÏ†ïÏÑ± ÌôïÎ≥¥**: Íµ≠ÎØºÏó∞Í∏àÏùÄ Ïû•Í∏∞Ï†ÅÏúºÎ°ú ÏßÄÏÜç Í∞ÄÎä•Ìïú Ïû¨Ï†ï Íµ¨Ï°∞Î•º Ïú†ÏßÄÌï¥Ïïº ÌïòÎ©∞, Ïù¥Îäî Ìñ•\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== checkpoint-900 ===\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ? Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Îã§ÏùåÍ≥º Í∞ôÏäµÎãàÎã§:\n",
      "\n",
      "1. **Ï†ïÎ∂ÄÏùò Ïû¨Ï†ï ÏßÄÏõê**: Íµ≠ÎØºÏó∞Í∏àÏùÄ ÌòÑÏû¨ Ï†ïÎ∂ÄÏùò Ïû¨Ï†ï ÏßÄÏõêÏùÑ Î∞õÍ≥† ÏûàÏúºÎ©∞, Ïù¥Îäî Ïó∞Í∏à ÏàòÍ∏âÏûêÏùò ÏÉùÌôú ÏïàÏ†ïÏùÑ ÏúÑÌï¥ ÌïÑÏöîÌï©ÎãàÎã§. Í∑∏Îü¨ÎÇò Ï†ïÎ∂ÄÏùò Ïû¨Ï†ï ÏßÄÏõêÏù¥ Î∂ÄÏ°±ÌïòÎã§Îäî ÎπÑÌåêÏù¥ ÏûàÏúºÎ©∞, Ïù¥Îäî Íµ≠ÎØºÏó∞Í∏àÏùò ÏßÄÏÜç Í∞ÄÎä•ÏÑ±Ïóê ÏòÅÌñ•ÏùÑ Ï§Ñ Ïàò ÏûàÏäµÎãàÎã§.\n",
      "\n",
      "2. **Ïó∞Í∏à ÏàòÍ∏âÏûêÏùò ÏÉù\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoints_dir = \"results/qlora_qwen3_8b_v2\"\n",
    "checkpoints = sorted([ckpt for ckpt in os.listdir(checkpoints_dir) if ckpt.startswith(\"checkpoint\")])\n",
    "\n",
    "for ckpt in checkpoints:\n",
    "    adapter_path = os.path.join(checkpoints_dir, ckpt)\n",
    "    model_with_adapter = PeftModel.from_pretrained(model, adapter_path)\n",
    "    model_with_adapter.eval()\n",
    "\n",
    "    pipe = pipeline(\"text-generation\", model=model_with_adapter, tokenizer=tokenizer)\n",
    "    result = pipe(\"Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ï£ºÏöî ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ?\", max_new_tokens=100)[0][\"generated_text\"]\n",
    "    print(f\"=== {ckpt} ===\\n{result}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2193826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:33<00:00, 18.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from model_load import tokenizer, model\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20189e2",
   "metadata": {},
   "source": [
    "### 6.2 Î™®Îç∏ Î≥ëÌï©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c62d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/peft/peft_model.py:585: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.32.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.33.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.34.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.35.self_attn.o_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n",
      "/opt/miniconda/envs/team2_env/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:348: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Î≥ëÌï© Î∞è Ï†ÄÏû•ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "adapter_path = \"/home/NEUL77/NEUL/hf/results_v2/qlora_qwen3_8b_v2/\"\n",
    "model = PeftModel.from_pretrained(model, adapter_path)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "model.save_pretrained(\"/home/NEUL77/NEUL/merged_qwen3_8b_v2\")\n",
    "tokenizer.save_pretrained(\"/home/NEUL77/NEUL/merged_qwen3_8b_v2\")\n",
    "\n",
    "print(\"Î≥ëÌï© Î∞è Ï†ÄÏû•ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ac29b",
   "metadata": {},
   "source": [
    "### 6.3 Î™®Îç∏ ÏÑ±Îä• ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958780fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:32<00:00, 16.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïù¥ Î∞úÏ£ºÌïú Ïù¥Îü¨ÎãùÏãúÏä§ÌÖú Í¥ÄÎ†® ÏÇ¨ÏóÖ ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ Ï†ïÎ¶¨Ìï¥ Ï§ò. Î∂ÑÏÑùÏùÑ ÏúÑÌïú Í∏∞Ï¥à ÏûêÎ£åÎ°ú ÌôúÏö©Ìï† ÏòàÏ†ïÏù¥Ïïº.\n",
      "Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïùò Ïù¥Îü¨ÎãùÏãúÏä§ÌÖú Í¥ÄÎ†® ÏÇ¨ÏóÖ ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ Ï†ïÎ¶¨Ìï¥ Ï£ºÏãúÎ†§Î©¥, Ìï¥Îãπ ÏãúÏä§ÌÖúÏùò Ï£ºÏöî Í∏∞Îä•, ÏöîÍµ¨ÏÇ¨Ìï≠, Ïö¥ÏòÅ ÌôòÍ≤Ω, Î≥¥Ïïà Î∞è Í∞úÏù∏Ï†ïÎ≥¥ Ï≤òÎ¶¨, Î≤ïÏ†Å Í∑úÏ†ú, ÏÇ¨Ïö©Ïûê Í≤ΩÌóò(UX) Îì±ÏùÑ Ìè¨Ìï®Ìï¥Ïïº Ìï©ÎãàÎã§. ÏïÑÎûòÎäî ÏùºÎ∞òÏ†ÅÏù∏ Í∏∞Ï§ÄÏùÑ Î∞îÌÉïÏúºÎ°ú Ìïú ÏòàÏãúÏûÖÎãàÎã§. Ïã§Ï†ú ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÄ Í≥µÎã®Ïùò Í≥µÏãù Î¨∏ÏÑúÎÇò ÏöîÏ≤≠ÏÑúÏóê Î™ÖÏãúÎêú ÎÇ¥Ïö©ÏùÑ Ï∞∏Í≥†Ìï¥Ïïº Ìï©ÎãàÎã§.\n",
      "\n",
      "---\n",
      "\n",
      "## **Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã® Ïù¥Ìïô(Ïù¥Îü¨Îãù) ÏãúÏä§ÌÖú ÏÇ¨ÏóÖ ÏöîÍµ¨ÏÇ¨Ìï≠ ÏöîÏïΩ**\n",
      "\n",
      "### 1. **ÏãúÏä§ÌÖú Í∞úÏöî**\n",
      "- **ÏãúÏä§ÌÖúÎ™Ö**: Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã® Ïù¥Îü¨Îãù ÏãúÏä§ÌÖú\n",
      "- **Î™©Ï†Å**: ÏßÅÏõê Î∞è Í≥†Í∞ù ÎåÄÏÉÅ ÍµêÏú°/ÌïôÏäµ Í∏∞Îä• Ï†úÍ≥µ\n",
      "- **Ïö¥ÏòÅ Í∏∞Í∞Ñ**: 5~10ÎÖÑ (Í≥ÑÏïΩ Í∏∞Í∞ÑÏóê Îî∞Îùº Îã¨ÎùºÏßê)\n",
      "- **Ïö¥ÏòÅ ÌôòÍ≤Ω**: ÌÅ¥ÎùºÏö∞Îìú Í∏∞Î∞ò, Î™®Î∞îÏùº Î∞è Îç∞Ïä§ÌÅ¨ÌÜ± Ìò∏Ìôò\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Ï£ºÏöî Í∏∞Îä• ÏöîÍµ¨ÏÇ¨Ìï≠**\n",
      "#### (1) **ÌïôÏäµ Í¥ÄÎ¶¨**\n",
      "- **ÏΩîÏä§/Í≥ºÏ†ï Í¥ÄÎ¶¨**: ÌïôÏäµ ÏΩòÌÖêÏ∏† ÏÉùÏÑ±, Î∂ÑÎ•ò, Î∞∞Ïπò\n",
      "- **ÌïôÏäµ Ìé∏ÏÑ±**: ÏÇ¨Ïö©ÏûêÎ≥Ñ ÎßûÏ∂§Ìòï ÌïôÏäµ Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
      "- **ÌïôÏäµ Í∏∞Î°ù Ï∂îÏ†Å**: ÌïôÏäµ ÏãúÍ∞Ñ, ÏôÑÎ£å Ïó¨Î∂Ä, ÏÑ±Ï†Å Îì± Í∏∞Î°ù\n",
      "- **ÌïôÏäµ ÏÑ±Í≥º Î∂ÑÏÑù**: ÏÇ¨Ïö©ÏûêÎ≥Ñ ÌïôÏäµ ÏÑ±Í≥º ÏãúÍ∞ÅÌôî Î∞è Î≥¥Í≥†\n",
      "\n",
      "#### (2) **ÌïôÏäµ ÏΩòÌÖêÏ∏† Í¥ÄÎ¶¨**\n",
      "- **ÏΩòÌÖêÏ∏† Ï†úÏûë**: ÎπÑÎîîÏò§, Î¨∏ÏÑú, ÌÄ¥Ï¶à Îì± Îã§ÏñëÌïú ÌòïÏãù ÏßÄÏõê\n",
      "- **ÏΩòÌÖêÏ∏† Í≥µÏú†**: ÎÇ¥Î∂Ä/Ïô∏Î∂Ä ÏÇ¨Ïö©Ïûê Í∞Ñ ÏΩòÌÖêÏ∏† Í≥µÏú† Í∏∞Îä•\n",
      "- **ÏΩòÌÖêÔøΩ Í≤ÄÏÉâ**: ÌÇ§ÏõåÎìú, Ïπ¥ÌÖåÍ≥†Î¶¨, ÎÇúÏù¥ÎèÑ Îì± Í∏∞Î∞ò Í≤ÄÏÉâ\n",
      "\n",
      "#### (3) **ÏÇ¨Ïö©Ïûê Í¥ÄÎ¶¨**\n",
      "- **ÏÇ¨Ïö©Ïûê Îì±Î°ù/Í¥ÄÎ¶¨**: ÏßÅÏõê, Í≥†Í∞ù Îì± Îã§ÏñëÌïú ÏÇ¨Ïö©Ïûê Ïú†Ìòï ÏßÄÏõê\n",
      "- **Ï†ëÍ∑º Í∂åÌïú ÏÑ§Ï†ï**: Ïó≠Ìï† Í∏∞Î∞ò Ï†ëÍ∑º Ï†úÏñ¥(RBAC)\n",
      "- **ÏÇ¨Ïö©ÏûêÎ≥Ñ ÏÑ§Ï†ï**: ÌïôÏäµ Í∏∞Í∞Ñ, ÌïôÏäµ Î™©Ìëú Îì± ÏÑ§Ï†ï\n",
      "\n",
      "#### (4) **Î™®Î∞îÏùº Î∞è Î©ÄÌã∞ÎîîÎ∞îÏù¥Ïä§ ÏßÄÏõê**\n",
      "- **Î™®Î∞îÏùº Ìò∏Ìôò**: Ïä§ÎßàÌä∏Ìè∞, ÌÉúÎ∏îÎ¶ø Îì± Îã§ÏñëÌïú Í∏∞Í∏∞ ÏßÄÏõê\n",
      "- **Ïò§ÌîÑÎùºÏù∏ ÌïôÏäµ**: Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Ïò§ÌîÑÎùºÏù∏ ÏÇ¨Ïö© Í∏∞Îä•\n",
      "\n",
      "#### (5) **Î≥¥Ïïà Î∞è Í∞úÏù∏Ï†ïÎ≥¥ Ï≤òÎ¶¨**\n",
      "- **ÏïîÌò∏Ìôî**: Îç∞Ïù¥ÌÑ∞ Ï†ÑÏÜ° Î∞è Ï†ÄÏû• Ïãú ÏïîÌò∏Ìôî\n",
      "- **Ï†ëÍ∑º Ï†úÏñ¥**: Í∞ïÎ†•Ìïú Î°úÍ∑∏Ïù∏ Ï†ïÏ±Ö Î∞è 2FA ÏßÄÏõê\n",
      "- **Í∞úÏù∏Ï†ïÎ≥¥ Ï≤òÎ¶¨**: GDPR Î∞è Í∞úÏù∏Ï†ïÎ≥¥ Î≥¥Ìò∏Î≤ï Ï§ÄÏàò\n",
      "- **Î°úÍ∑∏ Î∞è Í∞êÏÇ¨ Ï∂îÏ†Å**: ÏÇ¨Ïö©Ïûê ÌôúÎèô Î°úÍ∑∏ Í∏∞Î°ù Î∞è Í∞êÏÇ¨ Í∏∞Îä•\n",
      "\n",
      "#### (6) **Î≤ïÏ†Å Î∞è Í∑úÏ†ú Ï§ÄÏàò**\n",
      "- **Î≤ïÍ∑ú Ï§ÄÏàò**: Í∞úÏù∏Ï†ïÎ≥¥ Î≥¥Ìò∏Î≤ï, Ï†ïÎ≥¥ÌÜµÏã†ÎßùÎ≤ï Îì± Ï§ÄÏàò\n",
      "- **Î≥¥Ïïà Í∏∞Ï§Ä**: KISA Î≥¥Ïïà Í∞ïÌôîÏßÄÏπ® Ï§ÄÏàò\n",
      "- **Í≥ÑÏïΩ Í∑úÏ†ú**: Í≥µÎã®Ïùò ÏöîÍµ¨ÏÇ¨Ìï≠ Î∞è Í≥ÑÏïΩ Ï°∞Í±¥ Ï§ÄÏàò\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Í∏∞Ïà† ÏöîÍµ¨ÏÇ¨Ìï≠**\n",
      "- **ÌîåÎû´Ìèº**: Ïõπ/Î™®Î∞îÏùº Í∏∞Î∞ò (React, Angular, Flutter Îì±)\n",
      "- **Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§**: Í¥ÄÍ≥ÑÌòï DB Î∞è NoSQL Í∏∞Î∞ò\n",
      "- **API ÏßÄÏõê**: RESTful API, OAuth 2.0 Ïù∏Ï¶ù ÏßÄÏõê\n",
      "- **ÌÅ¥ÎùºÏö∞Îìú ÌôòÍ≤Ω**: AWS, Azure,ÈòøÈáå ÌÅ¥ÎùºÏö∞Îìú Îì±\n",
      "- **Î≥¥Ïïà Í∏∞Ïà†**: WAF, DDoS Î∞©Ïñ¥, Ïù∏Ï¶ù/Ïù∏Í∞Ä ÏãúÏä§ÌÖú\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **Ïö¥ÏòÅ Î∞è Ïú†ÏßÄÎ≥¥Ïàò**\n",
      "- **Ïö¥ÏòÅ Î™®Îìú**: SaaS ÎòêÎäî PaaS ÌòïÌÉú Ïö¥ÏòÅ\n",
      "- **Î∞±ÏóÖ Î∞è Î≥µÍµ¨**: Ï†ïÍ∏∞Ï†Å Î∞±ÏóÖ Î∞è Ïû¨Ìï¥ Î≥µÍµ¨ Í≥ÑÌöç\n",
      "- **ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Ïú†ÏßÄÎ≥¥Ïàò**: Ï†ïÍ∏∞Ï†Å ÏóÖÎç∞Ïù¥Ìä∏ Î∞è Ïù¥Ïäà ÎåÄÏùë\n",
      "\n",
      "---\n",
      "\n",
      "### 5. **ÏÇ¨Ïö©Ïûê Í≤ΩÌóò (UX)**\n",
      "- **Ïù∏ÌÑ∞ÌéòÏù¥Ïä§**: ÏßÅÍ¥ÄÏ†ÅÏù∏ UI/UX ÎîîÏûêÏù∏\n",
      "- **Ï†ëÍ∑ºÏÑ±**: Ïû•Ïï†Ïù∏ Ï†ëÍ∑ºÏÑ± Í∏∞Ï§Ä Ï§ÄÏàò\n",
      "- **Îã§Íµ≠Ïñ¥ ÏßÄÏõê**: ÌïúÍ∏Ä, ÏòÅÎ¨∏ Îì± ÏßÄÏõê\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model_path = \"/home/NEUL77/NEUL/merged_qwen3_8b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=\"auto\", torch_dtype=torch.float16, trust_remote_code=True)\n",
    "\n",
    "input_text = \"Íµ≠ÎØºÏó∞Í∏àÍ≥µÎã®Ïù¥ Î∞úÏ£ºÌïú Ïù¥Îü¨ÎãùÏãúÏä§ÌÖú Í¥ÄÎ†® ÏÇ¨ÏóÖ ÏöîÍµ¨ÏÇ¨Ìï≠ÏùÑ Ï†ïÎ¶¨Ìï¥ Ï§ò.\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=1000)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd71ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "team2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
